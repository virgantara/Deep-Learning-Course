{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":242592,"sourceType":"datasetVersion","datasetId":102285},{"sourceId":11095620,"sourceType":"datasetVersion","datasetId":6916696}],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.nn.functional as F\n\nimport os\nimport struct\nimport numpy as np\n\nfrom tqdm import tqdm\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:53:12.912267Z","iopub.execute_input":"2025-03-20T01:53:12.912602Z","execution_failed":"2025-03-20T01:53:46.418Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def read_idx(filename):\n    \"\"\"Read IDX file format\"\"\"\n    with open(filename, 'rb') as f:\n        zero, data_type, dims = struct.unpack('>HBB', f.read(4))\n        shape = tuple(struct.unpack('>I', f.read(4))[0] for d in range(dims))\n        return np.frombuffer(f.read(), dtype=np.uint8).reshape(shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-20T01:53:12.918276Z","iopub.execute_input":"2025-03-20T01:53:12.918589Z","iopub.status.idle":"2025-03-20T01:53:12.934435Z","shell.execute_reply.started":"2025-03-20T01:53:12.918564Z","shell.execute_reply":"2025-03-20T01:53:12.933547Z"}},"outputs":[],"execution_count":75},{"cell_type":"markdown","source":"# Load Dataset","metadata":{}},{"cell_type":"code","source":"import torch\nfrom torch.utils.data import Dataset\nimport torchvision.transforms as transforms\n\nclass CustomMNISTDataset(Dataset):\n    def __init__(self, images, labels, transform=None):\n        self.images = images\n        self.labels = labels\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.images)\n\n    def __getitem__(self, idx):\n        image = self.images[idx]\n        label = self.labels[idx]\n\n        image = torch.tensor(image, dtype=torch.float32)\n        image = image / 255.0\n        image = image.unsqueeze(0)  # (1, 28, 28)\n\n        if self.transform:\n            image = self.transform(image)\n\n        return image, label\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_transform = transforms.Compose([\n    transforms.RandomRotation(15),\n    transforms.RandomCrop(28, padding=4),\n    transforms.Normalize((0.5,), (0.5,))\n])\n\ntest_transform = transforms.Compose([\n    transforms.Normalize((0.5,), (0.5,))\n])","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_dir = '/kaggle/input/mnist-dataset'\n\ntrain_images = read_idx(os.path.join(data_dir, 'train-images.idx3-ubyte'))\ntrain_labels = read_idx(os.path.join(data_dir, 'train-labels.idx1-ubyte'))\n\ntest_images = read_idx(os.path.join(data_dir, 't10k-images.idx3-ubyte'))\ntest_labels = read_idx(os.path.join(data_dir, 't10k-labels.idx1-ubyte'))\n\nprint(f\"Train images shape: {train_images.shape}\")  # (60000, 28, 28)\nprint(f\"Train labels shape: {train_labels.shape}\")  # (60000,)\n\nprint(f\"Test images shape: {test_images.shape}\")  # (10000, 28, 28)\nprint(f\"Test labels shape: {test_labels.shape}\")  # (10000,)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.421Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = CustomMNISTDataset(train_images, train_labels, transform=train_transform)\ntest_dataset = CustomMNISTDataset(test_images, test_labels, transform=test_transform)\n\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Device configuration (use GPU if available)","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.421Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"batch_size = 64\nlearning_rate = 0.001\nnum_epochs = 5","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.422Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model CNN","metadata":{}},{"cell_type":"code","source":"class ModelCNN(nn.Module):\n    def __init__(self):\n        super(ModelCNN, self).__init__()\n        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size =5, padding=2)\n        self.pool = nn.MaxPool2d(kernel_size=2, stride = 2)\n\n        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16,kernel_size=5)\n        \n        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Linear(84, 10)\n\n    def forward(self, x):\n        x = F.relu(self.conv1(x))\n        x = self.pool(x)\n        x = F.relu(self.conv2(x))\n        x = self.pool(x)\n        x = torch.flatten(x, 1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        \n        return x","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.422Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = ModelCNN().to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=learning_rate)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.423Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for epoch in tqdm(range(num_epochs)):\n    model.train()\n    for images, labels in train_loader:\n        images, labels = images.to(device), labels.to(device)\n\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    \n    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.423Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import (\n    confusion_matrix, ConfusionMatrixDisplay,\n    accuracy_score, precision_score, recall_score, \n    f1_score, classification_report\n)\nimport matplotlib.pyplot as plt\n\nmodel.eval()\ny_true = []\ny_pred = []\n\nwith torch.no_grad():\n    for images, labels in test_loader:\n        images, labels = images.to(device), labels.to(device)\n        outputs = model(images)\n        _, predicted = torch.max(outputs.data, 1)\n        \n        y_true.extend(labels.cpu().numpy())\n        y_pred.extend(predicted.cpu().numpy())\n\ncm = confusion_matrix(y_true, y_pred)\n\ndisp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[0,1,2,3,4,5,6,7,8,9])\ndisp.plot(cmap=plt.cm.Blues)\nplt.title('Confusion Matrix')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.424Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\nprint(f\"Precision (macro): {precision_score(y_true, y_pred, average='macro'):.4f}\")\nprint(f\"Recall (macro): {recall_score(y_true, y_pred, average='macro'):.4f}\")\nprint(f\"F1-Score (macro): {f1_score(y_true, y_pred, average='macro'):.4f}\")\n\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred))\n\n\nFP = cm.sum(axis=0) - np.diag(cm)\nFN = cm.sum(axis=1) - np.diag(cm)\nTP = np.diag(cm)\nTN = cm.sum() - (FP + FN + TP)\n\nFPR = FP / (FP + TN)\nTPR = TP / (TP + FN)\n\nfor i in range(len(TP)):\n    print(f\"Kelas {i}: FPR = {FPR[i]:.4f}, TPR (Recall) = {TPR[i]:.4f}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.424Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Simpan model untuk prediksi","metadata":{}},{"cell_type":"code","source":"torch.save(model.state_dict(), 'model_cnn_mnist.pth')\n# model.load_state_dict(torch.load('cnn_mnist.pth'))\n\ntorch.save(model, 'cnn_mnist_full.pth')\n# model = torch.load('cnn_mnist_full.pth')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.425Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Prediksi citra tulisan tangan dengan data selain data ujicoba","metadata":{}},{"cell_type":"code","source":"from PIL import Image\n\nmodel = ModelCNN()\nmodel.load_state_dict(torch.load('/kaggle/working/model_cnn_mnist.pth'))\nmodel.eval()\n\ntransform = transforms.Compose([\n    transforms.Grayscale(num_output_channels=1),  \n    transforms.Resize((28, 28)),                  \n    transforms.ToTensor(),                        \n    transforms.Normalize((0.5,), (0.5,))          \n])\n\nimage_path = '/kaggle/input/sampel-handwritten-number/6.jpg'  \nimage = Image.open(image_path)\nimage = transform(image)               \nimage = image.unsqueeze(0)             \n\nwith torch.no_grad():\n    output = model(image)\n    _, predicted = torch.max(output.data, 1)\n\nprint(f'Predicted Class: {predicted.item()}')","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-20T01:53:46.425Z"}},"outputs":[],"execution_count":null}]}